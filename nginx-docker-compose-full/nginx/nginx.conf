# ==========================================
# NGINX Main Configuration
# ==========================================

# User context - security isolation
# Options: nginx, www-data, nobody
# For container: nginx (default), for system: www-data
user  nginx;

# Worker process configuration
# Options: auto (CPU cores), number (1-8), or specific count
# auto = automatically detect CPU cores
# Alternatives: 1, 2, 4, 8 (match your server CPU cores)
worker_processes  ${WORKER_PROCESSES:-auto};

# Maximum file descriptors per worker
# Options: 1024-65535 (higher for high traffic)
# Recommended: 2x worker_connections
worker_rlimit_nofile ${WORKER_RLIMIT_NOFILE:-65535};

# Error log configuration
# Log levels: debug, info, notice, warn, error, crit, alert, emerg
# Locations: /var/log/nginx/error.log, stderr, syslog:server=unix:/dev/log
error_log  /var/log/nginx/error.log ${LOG_LEVEL:-warn};

# Process ID file location
# Default: /var/run/nginx.pid
# Alternative: /run/nginx.pid, /tmp/nginx.pid
pid        /var/run/nginx.pid;

# ==========================================
# Events Block - Connection Processing
# ==========================================
events {
    # Maximum connections per worker process
    # Options: 1024 (default), 2048, 4096, 8192
    # Formula: worker_processes Ã— worker_connections = max connections
    # For high traffic: 4096-8192, for normal: 1024-2048
    worker_connections  ${WORKER_CONNECTIONS:-4096};
    
    # Connection processing method (Linux)
    # Options: epoll (Linux), kqueue (BSD), select (universal)
    # epoll: most efficient for Linux
    # kqueue: most efficient for BSD/macOS
    use epoll;
    
    # Accept multiple connections at once
    # Options: on (recommended), off
    # Improves performance under high load
    multi_accept on;
    
    # Additional options:
    # accept_mutex on;        # Serialize accept() calls (default: off)
    # accept_mutex_delay 500ms; # Delay between accept attempts
    # worker_aio_requests 32;   # AIO requests per worker (if AIO enabled)
}

# ==========================================
# HTTP Block - Main Configuration
# ==========================================
http {
    # ==========================================
    # Basic Settings
    # ==========================================
    
    # MIME types mapping
    # Include standard MIME types for file serving
    include       /etc/nginx/mime.types;
    
    # Default MIME type for unknown files
    # Options: application/octet-stream, text/plain
    default_type  application/octet-stream;
    
    # ==========================================
    # Security Settings
    # ==========================================
    
    # Hide NGINX version in headers and error pages
    # Options: on (show version), off (hide version), build (show build)
    # Recommended: off (security through obscurity)
    server_tokens off;
    
    # Additional security options:
    # more_set_headers "Server: Custom-Server";  # Requires headers-more module
    # server_names_hash_bucket_size 64;          # Server name hash bucket size
    
    # ==========================================
    # Performance Settings
    # ==========================================
    
    # Efficient file serving using kernel sendfile()
    # Options: on (recommended), off
    # Faster than read() + write() for static files
    sendfile        on;
    
    # Send headers and file content in one packet
    # Options: on (recommended with sendfile), off
    # Reduces network overhead
    tcp_nopush      on;
    
    # Disable Nagle's algorithm for real-time applications
    # Options: on (recommended), off
    # Reduces latency for small packets
    tcp_nodelay     on;
    
    # Keep-alive connection timeout
    # Options: 30-75 seconds (recommended: 65)
    # Longer: fewer connections, more memory
    # Shorter: more connections, less memory
    keepalive_timeout  ${KEEPALIVE_TIMEOUT:-65};
    
    # Maximum requests per keep-alive connection
    # Options: 100-1000 (recommended: 100-500)
    # Higher: better performance, more memory usage
    keepalive_requests ${KEEPALIVE_REQUESTS:-100};
    
    # Maximum client request body size
    # Options: 1M, 8M, 16M, 50M, 100M
    # For file uploads, API requests
    client_max_body_size ${CLIENT_MAX_BODY_SIZE:-16M};
    
    # Client body read timeout
    # Options: 5-60 seconds (recommended: 12)
    client_body_timeout ${CLIENT_BODY_TIMEOUT:-12};
    
    # Client header read timeout
    # Options: 5-60 seconds (recommended: 12)
    client_header_timeout ${CLIENT_HEADER_TIMEOUT:-12};
    
    # Response send timeout
    # Options: 5-60 seconds (recommended: 10)
    send_timeout ${SEND_TIMEOUT:-10};
    
    # Additional performance options:
    # reset_timedout_connection on;  # Reset timed out connections
    # open_file_cache max=1000 inactive=20s;  # File descriptor cache
    # open_file_cache_valid 30s;     # Cache validation interval
    # open_file_cache_min_uses 2;    # Minimum uses before caching
    
    # ==========================================
    # Buffer Settings
    # ==========================================
    
    # Client request body buffer size
    # Options: 8K, 10K, 16K, 32K
    # Larger buffers = fewer disk writes for large requests
    # Smaller buffers = less memory usage
    client_body_buffer_size ${CLIENT_BODY_BUFFER_SIZE:-10K};
    
    # Client request header buffer size
    # Options: 1k (default), 2k, 4k
    # Increase if you have large headers (cookies, tokens)
    client_header_buffer_size ${CLIENT_HEADER_BUFFER_SIZE:-1k};
    
    # Large client header buffers
    # Format: number size (e.g., 2 1k, 4 4k, 8 8k)
    # For requests with large headers (OAuth tokens, cookies)
    large_client_header_buffers ${LARGE_CLIENT_HEADER_BUFFERS:-2 1k};
    
    # Additional buffer options:
    # client_body_in_file_only clean;     # Store request body in temp file
    # client_body_in_single_buffer on;    # Store in single buffer
    # proxy_buffering on;                 # Enable proxy buffering
    # proxy_buffer_size 4k;               # Initial proxy buffer
    # proxy_buffers 8 4k;                 # Proxy response buffers
    
    # ==========================================
    # Gzip Compression Settings
    # ==========================================
    
    # Enable gzip compression
    # Options: on (recommended), off
    gzip ${GZIP_ENABLED:-on};
    
    # Add Vary: Accept-Encoding header
    # Options: on (recommended), off
    # Helps with caching proxies
    gzip_vary on;
    
    # Minimum file size to compress
    # Options: 20, 1000, 1024 (bytes)
    # Don't compress tiny files (overhead > benefit)
    gzip_min_length ${GZIP_MIN_LENGTH:-1000};
    
    # Compress proxied requests
    # Options: off, expired, no-cache, no-store, private, no_last_modified, no_etag, auth, any
    # any: compress all proxied requests (recommended)
    gzip_proxied ${GZIP_PROXIED:-any};
    
    # Compression level
    # Options: 1-9 (1=fastest, 9=best compression)
    # Recommended: 6 (good balance of speed vs compression)
    # 1-3: fast, low compression
    # 4-6: balanced (recommended)
    # 7-9: slow, high compression
    gzip_comp_level ${GZIP_COMP_LEVEL:-6};
    
    # Additional gzip options:
    # gzip_http_version 1.1;    # Minimum HTTP version to compress
    # gzip_disable "msie6";     # Disable for specific browsers
    # gunzip on;                # Decompress for clients that don't support gzip
    # MIME types to compress
    # Default: text/html is always compressed
    # Add/remove types based on your content
    gzip_types
        # Text content
        text/css                    # CSS stylesheets
        text/javascript            # JavaScript files
        text/plain                 # Plain text files
        text/xml                   # XML files
        
        # Application content
        application/atom+xml       # Atom feeds
        application/geo+json       # GeoJSON data
        application/javascript     # JavaScript (alternative MIME)
        application/x-javascript   # JavaScript (legacy MIME)
        application/json           # JSON data
        application/ld+json        # JSON-LD structured data
        application/manifest+json  # Web app manifests
        application/rdf+xml        # RDF XML
        application/rss+xml        # RSS feeds
        application/xhtml+xml      # XHTML content
        application/xml            # XML content
        
        # Font files
        font/eot                   # Embedded OpenType fonts
        font/otf                   # OpenType fonts
        font/ttf                   # TrueType fonts
        
        # Images (vector only - raster images shouldn't be compressed)
        image/svg+xml;             # SVG images
        
        # Additional types you might want:
        # application/pdf          # PDF files (usually already compressed)
        # application/zip          # ZIP files (already compressed)
        # image/x-icon            # ICO files
        # application/wasm        # WebAssembly files
    
    # ==========================================
    # Rate Limiting Configuration
    # ==========================================
    
    # Login endpoint rate limiting
    # zone=name:size rate=requests/time
    # 10r/m = 10 requests per minute
    # Alternative rates: 5r/m, 20r/m, 1r/s
    limit_req_zone $binary_remote_addr zone=login:${RATE_LIMIT_LOGIN_ZONE_SIZE:-10m} rate=${RATE_LIMIT_LOGIN:-10r/m};
    
    # API endpoint rate limiting  
    # 100r/m = 100 requests per minute
    # Alternative rates: 50r/m, 200r/m, 10r/s
    limit_req_zone $binary_remote_addr zone=api:${RATE_LIMIT_API_ZONE_SIZE:-10m} rate=${RATE_LIMIT_API:-100r/m};
    
    # General rate limiting
    # 1r/s = 1 request per second
    # Alternative rates: 5r/s, 10r/s, 2r/s
    limit_req_zone $binary_remote_addr zone=general:${RATE_LIMIT_GENERAL_ZONE_SIZE:-10m} rate=${RATE_LIMIT_GENERAL:-1r/s};
    
    # Additional rate limiting zones you can add:
    # limit_req_zone $binary_remote_addr zone=static:10m rate=10r/s;     # Static files
    # limit_req_zone $binary_remote_addr zone=upload:10m rate=1r/m;      # File uploads
    # limit_req_zone $server_name zone=perserver:10m rate=100r/s;        # Per server
    # limit_req_zone $request_uri zone=peruri:10m rate=5r/s;             # Per URI
    
    # ==========================================
    # Connection Limiting Configuration
    # ==========================================
    
    # Limit concurrent connections per IP
    # zone=name:size
    # Usage: limit_conn addr 10; (in server/location blocks)
    limit_conn_zone $binary_remote_addr zone=addr:${CONN_LIMIT_ZONE_SIZE:-10m};
    
    # Additional connection limiting zones:
    # limit_conn_zone $server_name zone=perserver:10m;       # Per server name
    # limit_conn_zone $request_uri zone=peruri:10m;          # Per URI
    # limit_conn_zone $binary_remote_addr zone=download:10m; # Download limits
    
    # Log Format
    log_format json_combined escape=json
    '{'
        '"time_local":"$time_local",'
        '"remote_addr":"$remote_addr",'
        '"remote_user":"$remote_user",'
        '"request":"$request",'
        '"status": "$status",'
        '"body_bytes_sent":"$body_bytes_sent",'
        '"request_time":"$request_time",'
        '"http_referrer":"$http_referer",'
        '"http_user_agent":"$http_user_agent",'
        '"http_x_forwarded_for":"$http_x_forwarded_for",'
        '"upstream_response_time":"$upstream_response_time",'
        '"upstream_addr":"$upstream_addr"'
    '}';
    
    access_log /var/log/nginx/access.log json_combined;
    
    # Security Headers (Global)
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;
    
    # SSL Settings
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;
    ssl_stapling on;
    ssl_stapling_verify on;
    
    # Upstream definitions
    upstream backend_app {
        least_conn;
        server app-1:80 weight=1 max_fails=3 fail_timeout=30s;
        server app-2:80 weight=1 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }
    
    # Status endpoint for monitoring
    server {
        listen 8080;
        server_name localhost;
        
        location /nginx_status {
            stub_status on;
            access_log off;
            allow 127.0.0.1;
            allow 10.0.0.0/8;
            allow 172.16.0.0/12;
            allow 192.168.0.0/16;
            deny all;
        }
        
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
    
    include /etc/nginx/conf.d/*.conf;
}
